{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backporting \"yield from\" to Python 2.7 \n",
    "\n",
    "__Or, How I Learned to Stop Worrying and Love the Generator__\n",
    "\n",
    "_a.k.a. \"AST Manipulation for Fun and Profit\"_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I know your initial reaction. \n",
    "\n",
    "\"2.7 is dead, get over it.\" \n",
    "\n",
    "\"Python 3 was released _ten years ago_.\" \n",
    "\n",
    "\"Clinging to the past like this is only _hurting_ the community!\"\n",
    "\n",
    "However, if you'll grant me the benefit of the doubt, I can promise you that this post will only incidentally be about Python 2.7, and (instead) mostly be about techniques and concepts that are equally well (better, even!) applied to Python 3.6, 3.7, and beyond."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motivation\n",
    "\n",
    "That being said, it is a _little_ about Python 2.7, so let's first motivate why we'd want to backport this feature. After all, a lot of people have no choice but to work on legacy 2.7 codebases, and never find themselves _needing_ (per se) a lot of what has been introduced in Python 3 - nice though it may be. What makes `yield from` special?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A bit about generators\n",
    "To start, it'd be helpful to know what `yield from` does. As you'll probably know already, generators are defined much like functions, but with a `yield` keyword that dictates what they will, well, _yield_. For instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def routes(starting_places, you_wanna_go=True, get_away_from_it_all=True):\n",
    "    destinations = ['aruba', 'jamaica', 'bermuda', 'bahama']\n",
    "    for starting_place in starting_places:\n",
    "        for destination in destinations:\n",
    "            if starting_place != destination:\n",
    "                yield (starting_place, destination)\n",
    "        if you_wanna_go and get_away_from_it_all:\n",
    "            yield (starting_place, 'kokomo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With our `routes` generator above, we can supply an iterable of starting places and get back all possible routes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('cleveland', 'aruba'),\n",
       " ('cleveland', 'jamaica'),\n",
       " ('cleveland', 'bermuda'),\n",
       " ('cleveland', 'bahama'),\n",
       " ('cleveland', 'kokomo')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(routes(starting_places=['cleveland']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, the best part (and a big differentiator from using e.g. a `for` loop or list comprehension) is that each of these values is not yielded by `routes` until we ask for it, meaning that we only perform the bare minimum computation. We can illustrate this by asking for our routes one at a time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We're dealing with a <type 'generator'>\n",
      "('lawrence, kansas', 'aruba')\n",
      "('lawrence, kansas', 'jamaica')\n",
      "Ooo, I wanna take ya\n",
      "('lawrence, kansas', 'bermuda')\n",
      "('lawrence, kansas', 'bahama')\n",
      "That should be the last of them, but let's give it one more shot.\n"
     ]
    },
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mStopIteration\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-e1a1ff7f127b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"That should be the last of them, but let's give it one more shot.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mStopIteration\u001b[0m: "
     ]
    }
   ],
   "source": [
    "g = routes(['lawrence, kansas'], get_away_from_it_all=False)\n",
    "print(\"We're dealing with a {!r}\".format(type(g)))\n",
    "print(next(g))\n",
    "print(next(g))\n",
    "print(\"Ooo, I wanna take ya\")\n",
    "print(next(g))\n",
    "print(next(g))\n",
    "print(\"That should be the last of them, but let's give it one more shot.\")\n",
    "print(next(g))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we've seen above, the pattern of repeatedly calling `next` on the generator until a `StopIteration` exception is raised, is actually a normal part of Python's iterator protocol - this is how, e.g., a `for` loop or comprehension knows when it's exhausted its target:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def numbers():\n",
    "    yield -1 + 2\n",
    "    yield 1 + 1\n",
    "    raise StopIteration(\"This should make a big mess if we don't expect it!\")\n",
    "    yield 9 / 3  # we never end up performing this division\n",
    "    yield 1 / 0  # or this one!\n",
    "    \n",
    "[number for number in numbers()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All in all, the \"[lazy](https://en.wikipedia.org/wiki/Lazy_evaluation)\" behavior of generators lets us do pretty interesting things, like representing infinite series without _computing_ infinite series, something that Haskell tutorials are weirdly insistent on bragging about:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...\n",
      "... ...\n",
      "... ... ...\n",
      "Ah, it's getting late, I should go...\n"
     ]
    }
   ],
   "source": [
    "def ellipses():\n",
    "    state = '...'\n",
    "    while True:\n",
    "        yield state\n",
    "        state += ' ...'\n",
    "        \n",
    "for ellipsis in ellipses():\n",
    "    print(ellipsis)\n",
    "    if len(ellipsis) >= 10:\n",
    "        print(\"Ah, it's getting late, I should go...\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Take_ that, _type safety!_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Yield from - what's the big whoop?\n",
    "\n",
    "So, then, if we know what `yield` does, what does `yield from` do? Well, it's more-or-less exactly what it says on the tin - it \"`yield`s `from`\" another generator! That is to say, `yield from` allows us to nest generators nicely. For instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def odd_numbers(max_number):\n",
    "    n = 1\n",
    "    while True:\n",
    "        yield n\n",
    "        n += 2\n",
    "        if n > max_number:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-7-7fefa543b1b7>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-7-7fefa543b1b7>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    yield from differnt_generator\u001b[0m\n\u001b[0m             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def good_ol_generator(differnt_generator):\n",
    "    yield \"startin'\"\n",
    "    yield from differnt_generator\n",
    "    yield \"that'n's finished, I reckon\"\n",
    "    \n",
    "for item in good_ol_generator(odd_numbers(4)):\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... would, if `yield from` were syntactically valid in Python 2.7, give us:\n",
    "```\n",
    "startin'\n",
    "1\n",
    "3\n",
    "that'n's finished, I reckon\n",
    "```\n",
    "... To which you might respond, \"That's all this is about? I can't believed I've been duped into reading this far.\"\n",
    "\n",
    "But, if you were just a bit more game (but similarly dismissive), you might equally respond, \"So what - can't you just do that with the following?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "startin'\n",
      "1\n",
      "3\n",
      "that'n's finished, I reckon\n"
     ]
    }
   ],
   "source": [
    "def good_ol_generator(differnt_generator):\n",
    "    yield \"startin'\"\n",
    "    for item in differnt_generator:\n",
    "        yield item\n",
    "    yield \"that'n's finished, I reckon\"\n",
    "    \n",
    "for item in good_ol_generator(odd_numbers(4)):\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The answer is: in a sense, yes, as you can clearly see above - but in a much deeper sense, no, not at all! To understand the nuance here, we'll need to know a bit more about generators."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating is a two-way street\n",
    "\n",
    "Let's take a step back. Remember when I said that generators only compute values when we ask for them? What exactly does that mean? Well, take (for example) the following generator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def mysterious_codes():\n",
    "    time.sleep(1)  # wait for the ideal opportunity...\n",
    "    yield \"The rooster has left the henhouse.\"\n",
    "    for number in range(100):\n",
    "        number * 2 - 1  # try to look inconspicuously busy...\n",
    "    yield \"The farmer is in the dell!\"\n",
    "    print(\"Last transmission, I've been compromised!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What gets executed, and when, when we run the following?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message 1: The rooster has left the henhouse.\n",
      "Message 2: The farmer is in the dell!\n",
      "Last transmission, I've been compromised!\n"
     ]
    },
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mStopIteration\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-7822cde31e95>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Message 2: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent_message\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Point D\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Message 3: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent_message\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;31m# Point E\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mStopIteration\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Point A\n",
    "agent_message = mysterious_codes()\n",
    "# Point B\n",
    "print(\"Message 1: {}\".format(next(agent_message)))\n",
    "# Point C\n",
    "print(\"Message 2: {}\".format(next(agent_message)))\n",
    "# Point D\n",
    "print(\"Message 3: {}\".format(next(agent_message)))\n",
    "# Point E"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we color-coded it (roughly), with <span style=\"color: white; background-color: #B03A2E\">red</span> being code run between points `A` and `B`, <span style=\"color: white; background-color: #8E44AD\">purple</span> being code run between `B` and `C`, <span style=\"color: white; background-color: #229954\">green</span> between `C` and `D`, and <span style=\"color: white; background-color: #2874A6\">blue</span> between `D` and `E`, it would look something like:\n",
    "\n",
    "<span style=\"font-family: Consolas, monospace; color: white\">\n",
    "<span style=\"background-color: #8E44AD\">\n",
    "time.sleep(1)&nbsp;&nbsp;# wait for the ideal opportunity...<br />\n",
    "yield \"The rooster has left the henhouse.\"<br />\n",
    "</span>\n",
    "<span style=\"background-color: #229954\">\n",
    "for number in range(100):<br />\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;number * 2 - 1&nbsp;&nbsp;# try to look inconspicuously busy...<br />\n",
    "yield \"The farmer is in the dell!\"<br />\n",
    "</span>\n",
    "<span style=\"background-color: #2874A6\">\n",
    "print(\"Last transmission, I've been compromised!\")<br />\n",
    "</span>\n",
    "</span>\n",
    "\n",
    "That is to say: when a generator is first instantiated (`agent_message = mysterious_codes()`), nothing is executed. Thereafter, each time `next` is called, the generator executes code until it reaches the next `yield` - then returns control back to the caller, returning as a value whatever followed `yield`. This continues (so long as `next` keeps getting called) until the generator either raises `StopIteration`, reaches a `return`, or reaches the end of the generator's definition (really, under the hood, an implicit `return`).\n",
    "\n",
    "From the perspective of the parent frame, the call to `next` is an indication to hand back control to the generator - i.e., in the code below, `next(agent_message)` is executed _before_ the purple block above, and the rest _afterward_ (after being returned the `yield`ed message).\n",
    "\n",
    "<span style=\"font-family: Consolas, monospace; color: white\">\n",
    "<span style=\"background-color: #8E44AD\">print(\"Message 1: {}\".format(<span style=\"background-color: #B03A2E\">next(agent_message)</span>))\n",
    "\n",
    "This, fundamentally, is really no different from, for example, calling a function during an assignment, e.g.:\n",
    "\n",
    "`result = calculate(x, y)`\n",
    "\n",
    ", in that the parent frame is yielding control to the `calculate` function and waiting for whatever it `return`s, before being able to assign that to `result`. \n",
    "\n",
    "What this all means is that _generators are a fundamental control flow mechanism in Python_. Whoever chose `yield` as the name of the generator keyword was a _genius_; \"yield\" in English can be used in one of two ways: a recipe can \"yield\" a dozen cookies, or a refining process can \"yield\" iron ingots from ore, but a car can also \"yield\" way to another car, or a ruler can \"yield\" their command to someone else. \"Yield\" signifies both production of some item or items via some process, as well as deference or delegation of control to something else - and Python's `yield` captures both these meanings _precisely_*.\n",
    "\n",
    "\\* _Although the second meaning didn't apply when the keyword was first introduced, so take what you will from this - either magnificent foresight, or an auspicious decision in hindsight._\n",
    "\n",
    "To illustrate: supposing we wanted to scrape all the links from some page. Let's say, however, that if the time to load the initial page was too slow, we'd rather just give up. One way of modeling this is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from lxml import etree\n",
    "\n",
    "def scrape_links(url):\n",
    "    result = requests.get(url)\n",
    "    link_urls = etree.HTML(result.content).xpath(\"//a/@href\")\n",
    "    if result.elapsed.total_seconds() > 0.25:\n",
    "        return\n",
    "    for link_url in link_urls:\n",
    "        yield requests.get(link_url)\n",
    "        \n",
    "def scrape_and_process(urls):\n",
    "    for url in urls:\n",
    "        scraped_pages = list(scrape_links(url))\n",
    "        process(scraped_pages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, what if we need the go/no-go logic to be more complex? Maybe rely on some context, such as how much time we've already spent scraping other sites, and how much time we have allotted total for this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scrape_links(url, spent_time, allotted_time):\n",
    "    result = requests.get(url)\n",
    "    link_urls = etree.HTML(result.content).xpath(\"//a/@href\")\n",
    "    remaining_time = allotted_time - (spent_time + result.elapsed.total_seconds())\n",
    "    if result.elapsed.total_seconds() * len(link_urls) > remaining_time:\n",
    "        return\n",
    "    for link_url in link_urls:\n",
    "        yield requests.get(link_url)\n",
    "        \n",
    "def scrape_and_process(urls):\n",
    "    max_time = 10  # seconds\n",
    "    start_time = time.time()\n",
    "    for url in urls:\n",
    "        scraped_pages = list(scrape_links(\n",
    "            url,\n",
    "            spent_time=time.time() - start_time,\n",
    "            allotted_time=max_time\n",
    "        ))\n",
    "        process(scraped_pages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But now, increasingly, our `scrape_links` function is looking less like it's about scraping links and more like it's about managing time - pretty unclean, with muddled responsibilities. \n",
    "\n",
    "If generators _weren't_ lazy, we'd probably have to solve this by doing something like the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scrape_links_part_1(url):\n",
    "    result = requests.get(url)\n",
    "    state = etree.HTML(result.content)\n",
    "    return result.elapsed.total_seconds(), state\n",
    "\n",
    "def scrape_links_part_2(previous_state):\n",
    "    link_urls = previous_state.xpath(\"//a/@href\")\n",
    "    for link_url in link_urls:\n",
    "        yield requests.get(link_url)\n",
    "        \n",
    "def scrape_and_process(urls):\n",
    "    max_time = 10  # seconds\n",
    "    start_time = time.time()\n",
    "    for url in urls:\n",
    "        initial_request_time, scrape_links_state = scrape_links_part_1(url)\n",
    "        if not ok_to_proceed(start_time, max_time, initial_request_time):\n",
    "            continue\n",
    "        scraped_pages = list(scrape_links_part_2(scrape_links_state))\n",
    "        process(scraped_pages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, the problem _now_ is that `scrape_and_process` for some reason is left having to temporarily hold onto the `scrape_links_state` from `scrape_links_part_1` - which _it_ doesn't necessarily care about.\n",
    "\n",
    "Thankfully, we can instead do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def scrape_links(url):\n",
    "    result = requests.get(url)\n",
    "    state = etree.HTML(result.content)\n",
    "    yield result.elapsed.total_seconds()\n",
    "    link_urls = state.xpath(\"//a/@href\")\n",
    "    for link_url in link_urls:\n",
    "        yield requests.get(link_url)\n",
    "        \n",
    "def scrape_and_process(urls):\n",
    "    max_time = 10  # seconds\n",
    "    start_time = time.time()\n",
    "    for url in urls:\n",
    "        g = scrape_links(url)\n",
    "        initial_request_time = next(g)  # our first yielded value\n",
    "        if not ok_to_proceed(start_time, max_time, initial_request_time):\n",
    "            continue\n",
    "        scraped_pages = list(g)  # all subsequent yielded values\n",
    "        process(scraped_pages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This way, `g` keeps its state entirely internal to itself - but also doesn't make any further requests without the go-ahead of `scrape_and_process`, the decision of which can be arbitrarily complex and _completely opaque_ to `scrape_links`*.\n",
    "\n",
    "\\* _One caveat - yes, this `does` mean that `result` and `state` persist in memory as long as we hold a reference to `g` from anywhere else in the code - since Python never knows whether we're going to resume its computation or not!_\n",
    "\n",
    "But now, here's the kicker: suppose we want `scape_links` to sometimes only request _some_ of the page's links - _as dictated by_ `scrape_and_process`. Are we going to be forced to go back to our two-part, two-function solution, and have the number of pages to scrape be passed in along with `previous_state`? Of course, we could just have `scrape_and_process` only call `next(g)` that many times - but supposing that we'd maybe want `scrape_links` to prioritize some links over others, based not only on the links themselves, but the number of pages to scrape? Maybe `.php` pages take 5 times longer on average than `.html` to request, but are much more valuable - but, if we're only going to be allowed to scrape a single page, that means the `.php` probably doesn't have time to load at all, and so we'd better try a `.html`? Are we just doomed?\n",
    "\n",
    "No! \n",
    "\n",
    "The trick is that there's another way entirely to prompt generators to resume calculation - a way that _also_ lets you send values _to_ the generator, enabling _two-way communication_. That way is the `.send` method. Here's a very simple example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator:\tInitial value was `hello`\n",
      "Generator:\tI got sent `world`!\n",
      "Calling frame:\tThe second thing on this side was `worldworld` - first was `hellohello`\n",
      "Generator:\tI got sent `goodbye` - but now I'm done.\n"
     ]
    },
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mStopIteration\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-099006cb903b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mfirst_yielded_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     ))\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'goodbye'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mStopIteration\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def sendable(initial_value):\n",
    "    print(\"Generator:\\tInitial value was `{}`\".format(initial_value))\n",
    "    sent_value = yield initial_value * 2\n",
    "    print(\"Generator:\\tI got sent `{}`!\".format(sent_value))\n",
    "    sent_value = yield sent_value * 2\n",
    "    print(\"Generator:\\tI got sent `{}` - but now I'm done.\".format(sent_value))\n",
    "\n",
    "g = sendable(initial_value='hello')\n",
    "first_yielded_value = next(g)\n",
    "if 'hello' in first_yielded_value:\n",
    "    second_yielded_value = g.send('world')\n",
    "    print(\"Calling frame:\\tThe second thing on this side was `{}` - first was `{}`\".format(\n",
    "        second_yielded_value,\n",
    "        first_yielded_value\n",
    "    ))\n",
    "    g.send('goodbye')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it transpires, `next(g)` is also actually equivalent to `g.send(None)` - and the [Python generator protocol](https://www.python.org/dev/peps/pep-0342/#new-generator-method-send-value), in fact, _requires_ that the first value sent to a newly initialized generator be `None`.\n",
    "\n",
    "With this now in mind, we can create exactly the version of `scrape_links` that we were hoping for:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def scrape_links(url):\n",
    "    result = requests.get(url)\n",
    "    state = etree.HTML(result.content)\n",
    "    num_allowed_requests = yield result.elapsed.total_seconds()\n",
    "    link_urls = state.xpath(\"//a/@href\")\n",
    "    for link_url in prioritized(link_urls, num_allowed_requests):\n",
    "        yield requests.get(link_url)\n",
    "        \n",
    "def scrape_and_process(urls):\n",
    "    max_time = 10  # seconds\n",
    "    start_time = time.time()\n",
    "    for url in urls:\n",
    "        g = scrape_links(url)\n",
    "        initial_request_time = next(g)\n",
    "        allowed_requests = calc_allowed_requests(start_time, max_time, initial_request_time)\n",
    "        if not allowed_requests:\n",
    "            continue\n",
    "        first_scraped_page = g.send(allowed_requests)\n",
    "        scraped_pages = list(g)\n",
    "        scraped_pages.append(first_scraped_page)\n",
    "        process(scraped_pages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we imagine that only one URL was allowed to be scraped, the periods of execution within `scrape_links` would look like the following (I've added the otherwise implicit `return` for illustrative purposes):\n",
    "\n",
    "<span style=\"font-family: Consolas, monospace; color: white\">\n",
    "<span style=\"background-color: #8E44AD\">\n",
    "result = requests.get(url)<br />\n",
    "state = etree.HTML(result.content)<br />\n",
    "</span>\n",
    "<span style=\"background-color: #229954\">num_allowed_requests</span><span style=\"background-color: white; color: black\"> = </span><span style=\"background-color: #8E44AD\">yield result.elapsed.total_seconds()</span><br />\n",
    "<span style=\"background-color: #229954\">\n",
    "link_urls = state.xpath(\"//a/@href\")<br />\n",
    "for link_url in prioritized(link_urls, num_allowed_requests):<br />\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;yield requests.get(link_url)<br />\n",
    "</span>\n",
    "<span style=\"background-color: #2874A6\">\n",
    "return&nbsp;&nbsp;# could also be raising StopIteration<br />\n",
    "</span>\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is two-way communication good for?\n",
    "\n",
    "The answer, broadly, is \"whatever coroutines are useful for\" - a topic [covered extensively and compellingly by David Beazley in a highly-recommended presentation](https://www.youtube.com/watch?v=Z_OAlIhXziw). As a succinct, bite-sized use case, however, consider the following:\n",
    "\n",
    "#### Batching\n",
    "Suppose we are reading in messages which we'd like to transform into rows to insert into a database. Suppose also that this process yields multiple rows, and that some properties of previously-inserted rows (e.g. the auto-incremented primary key ID assigned to them) must be used in the production of subsequent rows, e.g.:\n",
    "```\n",
    "{\n",
    " identification: {\n",
    "     name: \"McDonald, Ronald\",\n",
    "     fingerprint_sha: \"86d5bc08c2eba8\"\n",
    " },\n",
    " occupation: \"Fry cook\"\n",
    "}\n",
    "```\n",
    "being translated into a `occupations` table with `id` and `occupation_name` fields, and a `people` table with `id`, `name`, `fingerprint_sha`, and `occupation_id` fields. \n",
    "\n",
    "If we have many such messages, we may, for performance reasons, want to batch inserts into our database. We might accomplish this by instantiating one of the following generators for each message, and drawing from them simultaneously:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def parse_message(msg):\n",
    "    loaded = json.loads(msg)\n",
    "    occupation_id = yield Occupation(occupation_name=loaded['occupation'])\n",
    "    yield Person(\n",
    "        name=loaded['identification']['name'],\n",
    "        fingerprint_sha=loaded['identification']['fingerprint_sha'],\n",
    "        occupation_id=occupation_id\n",
    "    )\n",
    "    \n",
    "def bulk_load(messages):\n",
    "    message_parsers = [parse_message(msg) for msg in messages]\n",
    "    occupations = [next(parser) for parser in message_parsers]\n",
    "    occupation_ids = bulk_insert(occupations)\n",
    "    people = [\n",
    "        parser.send(occupation_id) \n",
    "        for parser, occupation_id in zip(message_parsers, occupation_ids)\n",
    "    ]\n",
    "    bulk_insert(people)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is easy to imagine that, for more complex or deeply-nested messages, mirroring the message structure via nested generators could potentially be an elegant and desirable design choice - if possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Back to \"yield from\"\n",
    "\n",
    "Let's look back now at the \"simple\" Python 2.7 equivalent to `yield from` that I proposed earlier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generator_a():\n",
    "    yield a\n",
    "    for item in generator_b:  # instead of \"yield from generator_b\"\n",
    "        yield item\n",
    "    yield z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The key problem here should now be very apparent - we can't propagate `.send` values to `generator_b` - and this is exactly what Python 3's `yield from` accomplishes. Without this, we end up either being unable to nest generators that require the use of `.send`, or must, as with the web scraping example I presented, make `generator_a` aware of (and handle) the state of `generator_b`. Lacking this makes it significantly harder to use regularly use generators as coroutines within your codebase, since, as you do, you become more and more likely to encounter situations in which the caller must have unmitigated communication with any and all components of the system. \n",
    "\n",
    "Simply put, without `yield from`, you cannot gain the full benefits of Python's generators - all the features of which are otherwise available in Python 2.7."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backporting\n",
    "\n",
    "Hopefully, I've now convinced you not only that generators have the potential to be incredibly useful, but also that having a `yield from` equivalent in Python 2.7 is a prerequisite for fully realizing that potential. \n",
    "\n",
    "How can we do so?\n",
    "\n",
    "[PEP-380](https://www.python.org/dev/peps/pep-0380/#formal-semantics) precisely defines the meaning of a `yield from` expression in the following way: \n",
    "\n",
    "```python\n",
    "def g():\n",
    "    EXPR = yield from RESULT\n",
    "```\n",
    "\n",
    "is equivalent to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def g():\n",
    "    _i = iter(EXPR)\n",
    "    try:\n",
    "        _y = next(_i)\n",
    "    except StopIteration as _e:\n",
    "        _r = _e.value\n",
    "    else:\n",
    "        while 1:\n",
    "            try:\n",
    "                _s = yield _y\n",
    "            except GeneratorExit as _e:\n",
    "                try:\n",
    "                    _m = _i.close\n",
    "                except AttributeError:\n",
    "                    pass\n",
    "                else:\n",
    "                    _m()\n",
    "                raise _e\n",
    "            except BaseException as _e:\n",
    "                _x = sys.exc_info()\n",
    "                try:\n",
    "                    _m = _i.throw\n",
    "                except AttributeError:\n",
    "                    raise _e\n",
    "                else:\n",
    "                    try:\n",
    "                        _y = _m(*_x)\n",
    "                    except StopIteration as _e:\n",
    "                        _r = _e.value\n",
    "                        break\n",
    "            else:\n",
    "                try:\n",
    "                    if _s is None:\n",
    "                        _y = next(_i)\n",
    "                    else:\n",
    "                        _y = _i.send(_s)\n",
    "                except StopIteration as _e:\n",
    "                    _r = _e.value\n",
    "                    break\n",
    "    RESULT = _r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ", which, of course, can be completely realized in Python 2.7. In fact, if you were so inclined, you could just use the above anywhere you'd want to use a `yield from` - at the expense of brevity, readability, maintainability, and, likely, sanity. \n",
    "\n",
    "What we'd _really_ like instead, I'd contend, is some way of getting Python to, whenever we have written `yield from` (or something similar), _copy and paste_ the above instead, before the code is ever run. Thankfully, Python gives us the tools to do just that!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Abstract Syntax Trees to the rescue!\n",
    "\n",
    "If you haven't heard of them before, Abstract Syntax Trees (hereafter, ASTs) give us a means of programmatically representing and manipulating source code - to build code that knows about code, just as we can build code that knows about databases or HTML documents. Via the AST, we can [create domain-specific languages](https://github.com/hchasestevens/xpyth), [write custom linting rules](https://github.com/hchasestevens/bellybutton), [search our codebases](https://github.com/hchasestevens/astpath), and even [automatically evolve code](https://github.com/hchasestevens/monkeys), all in a robust and easy way. Fully explaining the AST is a bit outside the scope of this piece, but those interested should take a look at the [green tree snakes guide to Python ASTs](https://greentreesnakes.readthedocs.io/en/latest/) as well as the [official Python `ast` module documentation](https://docs.python.org/3/library/ast.html).\n",
    "\n",
    "In order to perform the substitution I described above, we fundamentally need to define three things:\n",
    "  1. The pattern we want to replace.\n",
    "  2. What we'd like to replace it with.\n",
    "  3. A means of performing this replacement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identifying the pattern\n",
    "In terms of \\#1, we first need to decide on a syntactically valid equivalent to `yield from`. Since `from` is a reserved keyword in Python (making e.g. `yield from(EXPR)` impossible), the most straightforward equivalent is probably `yield_from(EXPR)`, or, if  assigning a result, `RESULT = yield_from(EXPR)`. We can use the `ast` module to see what these look like as represented in the AST:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Module(body=[Expr(value=Call(func=Name(id='yield_from', ctx=Load()), args=[Name(id='EXPR', ctx=Load())], keywords=[], starargs=None, kwargs=None))])\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "\n",
    "print(ast.dump(\n",
    "    ast.parse(\"\"\"yield_from(EXPR)\"\"\")\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Module(body=[Assign(targets=[Name(id='RESULT', ctx=Store())], value=Call(func=Name(id='yield_from', ctx=Load()), args=[Name(id='EXPR', ctx=Load())], keywords=[], starargs=None, kwargs=None))])\n"
     ]
    }
   ],
   "source": [
    "print(ast.dump(\n",
    "    ast.parse(\"\"\"RESULT = yield_from(EXPR)\"\"\")\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Noticeably, both are actually parsed as `Module`s, with single-element bodies - as if they were stand-alone files. Since we'll be expecting these to occur not alone, and not at module level, we can remove this superfluous root node and instead look at the node representing the expression itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expr(value=Call(func=Name(id='yield_from', ctx=Load()), args=[Name(id='EXPR', ctx=Load())], keywords=[], starargs=None, kwargs=None))\n"
     ]
    }
   ],
   "source": [
    "elem, = ast.parse(\"\"\"yield_from(EXPR)\"\"\").body\n",
    "print(ast.dump(elem))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assign(targets=[Name(id='RESULT', ctx=Store())], value=Call(func=Name(id='yield_from', ctx=Load()), args=[Name(id='EXPR', ctx=Load())], keywords=[], starargs=None, kwargs=None))\n"
     ]
    }
   ],
   "source": [
    "elem, = ast.parse(\"\"\"RESULT = yield_from(EXPR)\"\"\").body\n",
    "print(ast.dump(elem))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The key element of the `yield_from(EXPR)` case is the `Call` node: we are, fundamentally, performing a function call, with a function (`func`) that is the result of looking up (`Load()`) the `Name` with id `yield_from`, and supplying a single (positional) argument - in this case, the `Name` corresponding to our placeholder, `EXPR` (naturally, since we will want to replace `EXPR` with a generator of some sort, this will not be part of the pattern we're interested in). We can also use the tool [`showast`](https://github.com/hchasestevens/show_ast) to see what this looks like visually:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import showast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"260pt\" viewBox=\"0.00 0.00 352.39 260.00\" width=\"352pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 256)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"white\" points=\"-4,4 -4,-256 348.392,-256 348.392,4 -4,4\" stroke=\"none\"/>\n",
       "<!-- 0 -->\n",
       "<g class=\"node\" id=\"node1\"><title>0</title>\n",
       "<text fill=\"#004080\" font-family=\"Courier,monospace\" font-size=\"14.00\" font-weight=\"bold\" text-anchor=\"start\" x=\"183.594\" y=\"-230.8\">Expr</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g class=\"node\" id=\"node2\"><title>1</title>\n",
       "<text fill=\"#004080\" font-family=\"Courier,monospace\" font-size=\"14.00\" font-weight=\"bold\" text-anchor=\"start\" x=\"183.594\" y=\"-158.8\">Call</text>\n",
       "</g>\n",
       "<!-- 0&#45;&#45;1 -->\n",
       "<g class=\"edge\" id=\"edge1\"><title>0--1</title>\n",
       "<path d=\"M200.392,-215.697C200.392,-204.846 200.392,-190.917 200.392,-180.104\" fill=\"none\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g class=\"node\" id=\"node3\"><title>2</title>\n",
       "<text fill=\"#004080\" font-family=\"Courier,monospace\" font-size=\"14.00\" font-weight=\"bold\" text-anchor=\"start\" x=\"144.594\" y=\"-86.8\">Name</text>\n",
       "</g>\n",
       "<!-- 1&#45;&#45;2 -->\n",
       "<g class=\"edge\" id=\"edge2\"><title>1--2</title>\n",
       "<path d=\"M200.392,-143C200.392,-143 185.536,-123.192 174.162,-108.027\" fill=\"none\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 5 -->\n",
       "<g class=\"node\" id=\"node6\"><title>5</title>\n",
       "<text fill=\"#004080\" font-family=\"Courier,monospace\" font-size=\"14.00\" font-weight=\"bold\" text-anchor=\"start\" x=\"222.594\" y=\"-86.8\">Name</text>\n",
       "</g>\n",
       "<!-- 1&#45;&#45;5 -->\n",
       "<g class=\"edge\" id=\"edge5\"><title>1--5</title>\n",
       "<path d=\"M200.392,-143C200.392,-143 215.247,-123.192 226.622,-108.027\" fill=\"none\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g class=\"node\" id=\"node4\"><title>3</title>\n",
       "<text fill=\"#008040\" font-family=\"Courier,monospace\" font-size=\"14.00\" text-anchor=\"middle\" x=\"58.3916\" y=\"-13.8\">&quot;yield_from&quot;</text>\n",
       "</g>\n",
       "<!-- 2&#45;&#45;3 -->\n",
       "<g class=\"edge\" id=\"edge3\"><title>2--3</title>\n",
       "<path d=\"M151.392,-71C151.392,-71 115.966,-51.1921 88.8433,-36.0267\" fill=\"none\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g class=\"node\" id=\"node5\"><title>4</title>\n",
       "<text fill=\"#008040\" font-family=\"Courier,monospace\" font-size=\"14.00\" text-anchor=\"middle\" x=\"161.392\" y=\"-13.8\">Load</text>\n",
       "</g>\n",
       "<!-- 2&#45;&#45;4 -->\n",
       "<g class=\"edge\" id=\"edge4\"><title>2--4</title>\n",
       "<path d=\"M151.392,-71C151.392,-71 155.201,-51.1921 158.117,-36.0267\" fill=\"none\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 6 -->\n",
       "<g class=\"node\" id=\"node7\"><title>6</title>\n",
       "<text fill=\"#008040\" font-family=\"Courier,monospace\" font-size=\"14.00\" text-anchor=\"middle\" x=\"239.392\" y=\"-13.8\">&quot;EXPR&quot;</text>\n",
       "</g>\n",
       "<!-- 5&#45;&#45;6 -->\n",
       "<g class=\"edge\" id=\"edge6\"><title>5--6</title>\n",
       "<path d=\"M247.392,-71C247.392,-71 244.344,-51.1921 242.011,-36.0267\" fill=\"none\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 7 -->\n",
       "<g class=\"node\" id=\"node8\"><title>7</title>\n",
       "<text fill=\"#008040\" font-family=\"Courier,monospace\" font-size=\"14.00\" text-anchor=\"middle\" x=\"317.392\" y=\"-13.8\">Load</text>\n",
       "</g>\n",
       "<!-- 5&#45;&#45;7 -->\n",
       "<g class=\"edge\" id=\"edge7\"><title>5--7</title>\n",
       "<path d=\"M247.392,-71C247.392,-71 274.056,-51.1921 294.471,-36.0267\" fill=\"none\" stroke=\"black\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%showast\n",
    "yield_from(EXPR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will likewise notice that the case of `RESULT = yield_from(EXPR)` is the same with regards to the `Call` node, with only the addition of an `Assign` node (and the `Name` being assigned to):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"260pt\" viewBox=\"0.00 0.00 395.59 260.00\" width=\"396pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 256)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"white\" points=\"-4,4 -4,-256 391.594,-256 391.594,4 -4,4\" stroke=\"none\"/>\n",
       "<!-- 0 -->\n",
       "<g class=\"node\" id=\"node1\"><title>0</title>\n",
       "<text fill=\"#004080\" font-family=\"Courier,monospace\" font-size=\"14.00\" font-weight=\"bold\" text-anchor=\"start\" x=\"142.399\" y=\"-230.8\">Assign</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g class=\"node\" id=\"node2\"><title>1</title>\n",
       "<text fill=\"#004080\" font-family=\"Courier,monospace\" font-size=\"14.00\" font-weight=\"bold\" text-anchor=\"start\" x=\"113.797\" y=\"-158.8\">Name</text>\n",
       "</g>\n",
       "<!-- 0&#45;&#45;1 -->\n",
       "<g class=\"edge\" id=\"edge1\"><title>0--1</title>\n",
       "<path d=\"M167.594,-215C167.594,-215 153.5,-195.192 142.71,-180.027\" fill=\"none\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g class=\"node\" id=\"node5\"><title>4</title>\n",
       "<text fill=\"#004080\" font-family=\"Courier,monospace\" font-size=\"14.00\" font-weight=\"bold\" text-anchor=\"start\" x=\"187.797\" y=\"-158.8\">Call</text>\n",
       "</g>\n",
       "<!-- 0&#45;&#45;4 -->\n",
       "<g class=\"edge\" id=\"edge4\"><title>0--4</title>\n",
       "<path d=\"M167.594,-215C167.594,-215 181.688,-195.192 192.479,-180.027\" fill=\"none\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g class=\"node\" id=\"node3\"><title>2</title>\n",
       "<text fill=\"#008040\" font-family=\"Courier,monospace\" font-size=\"14.00\" text-anchor=\"middle\" x=\"41.5944\" y=\"-85.8\">&quot;RESULT&quot;</text>\n",
       "</g>\n",
       "<!-- 1&#45;&#45;2 -->\n",
       "<g class=\"edge\" id=\"edge2\"><title>1--2</title>\n",
       "<path d=\"M121.594,-143C121.594,-143 91.1208,-123.192 67.7894,-108.027\" fill=\"none\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g class=\"node\" id=\"node4\"><title>3</title>\n",
       "<text fill=\"#008040\" font-family=\"Courier,monospace\" font-size=\"14.00\" text-anchor=\"middle\" x=\"130.594\" y=\"-85.8\">Store</text>\n",
       "</g>\n",
       "<!-- 1&#45;&#45;3 -->\n",
       "<g class=\"edge\" id=\"edge3\"><title>1--3</title>\n",
       "<path d=\"M121.594,-143C121.594,-143 125.023,-123.192 127.647,-108.027\" fill=\"none\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 5 -->\n",
       "<g class=\"node\" id=\"node6\"><title>5</title>\n",
       "<text fill=\"#004080\" font-family=\"Courier,monospace\" font-size=\"14.00\" font-weight=\"bold\" text-anchor=\"start\" x=\"187.797\" y=\"-86.8\">Name</text>\n",
       "</g>\n",
       "<!-- 4&#45;&#45;5 -->\n",
       "<g class=\"edge\" id=\"edge5\"><title>4--5</title>\n",
       "<path d=\"M212.594,-143C212.594,-143 209.547,-123.192 207.214,-108.027\" fill=\"none\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 8 -->\n",
       "<g class=\"node\" id=\"node9\"><title>8</title>\n",
       "<text fill=\"#004080\" font-family=\"Courier,monospace\" font-size=\"14.00\" font-weight=\"bold\" text-anchor=\"start\" x=\"265.797\" y=\"-86.8\">Name</text>\n",
       "</g>\n",
       "<!-- 4&#45;&#45;8 -->\n",
       "<g class=\"edge\" id=\"edge8\"><title>4--8</title>\n",
       "<path d=\"M212.594,-143C212.594,-143 239.259,-123.192 259.674,-108.027\" fill=\"none\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 6 -->\n",
       "<g class=\"node\" id=\"node7\"><title>6</title>\n",
       "<text fill=\"#008040\" font-family=\"Courier,monospace\" font-size=\"14.00\" text-anchor=\"middle\" x=\"101.594\" y=\"-13.8\">&quot;yield_from&quot;</text>\n",
       "</g>\n",
       "<!-- 5&#45;&#45;6 -->\n",
       "<g class=\"edge\" id=\"edge6\"><title>5--6</title>\n",
       "<path d=\"M194.594,-71C194.594,-71 159.169,-51.1921 132.046,-36.0267\" fill=\"none\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 7 -->\n",
       "<g class=\"node\" id=\"node8\"><title>7</title>\n",
       "<text fill=\"#008040\" font-family=\"Courier,monospace\" font-size=\"14.00\" text-anchor=\"middle\" x=\"204.594\" y=\"-13.8\">Load</text>\n",
       "</g>\n",
       "<!-- 5&#45;&#45;7 -->\n",
       "<g class=\"edge\" id=\"edge7\"><title>5--7</title>\n",
       "<path d=\"M194.594,-71C194.594,-71 198.404,-51.1921 201.32,-36.0267\" fill=\"none\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 9 -->\n",
       "<g class=\"node\" id=\"node10\"><title>9</title>\n",
       "<text fill=\"#008040\" font-family=\"Courier,monospace\" font-size=\"14.00\" text-anchor=\"middle\" x=\"282.594\" y=\"-13.8\">&quot;EXPR&quot;</text>\n",
       "</g>\n",
       "<!-- 8&#45;&#45;9 -->\n",
       "<g class=\"edge\" id=\"edge9\"><title>8--9</title>\n",
       "<path d=\"M290.594,-71C290.594,-71 287.547,-51.1921 285.214,-36.0267\" fill=\"none\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 10 -->\n",
       "<g class=\"node\" id=\"node11\"><title>10</title>\n",
       "<text fill=\"#008040\" font-family=\"Courier,monospace\" font-size=\"14.00\" text-anchor=\"middle\" x=\"360.594\" y=\"-13.8\">Load</text>\n",
       "</g>\n",
       "<!-- 8&#45;&#45;10 -->\n",
       "<g class=\"edge\" id=\"edge10\"><title>8--10</title>\n",
       "<path d=\"M290.594,-71C290.594,-71 317.259,-51.1921 337.674,-36.0267\" fill=\"none\" stroke=\"black\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%showast\n",
    "RESULT = yield_from(EXPR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this, it's relatively easy, given a method of traversing all the nodes of some source code, to match on these patterns (albeit crudely):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LINE 4:\n",
      "Call(func=Name(id='yield_from', ctx=Load()), args=[Name(id='generator_b', ctx=Load())], keywords=[], starargs=None, kwargs=None)\n",
      "\n",
      "LINE 6:\n",
      "Call(func=Name(id='yield_from', ctx=Load()), args=[Name(id='generator_c', ctx=Load())], keywords=[], starargs=None, kwargs=None)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "code = \"\"\"\n",
    "def generator_a():\n",
    "    yield a\n",
    "    yield_from(generator_b)\n",
    "    yield b\n",
    "    yield_from(generator_c)\n",
    "    yield z\n",
    "\"\"\"\n",
    "\n",
    "def is_yield_from(ast_node):\n",
    "    if not isinstance(ast_node, ast.Call):\n",
    "        return False\n",
    "    if not isinstance(ast_node.func, ast.Name):\n",
    "        return False\n",
    "    if ast_node.func.id != 'yield_from':\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "parsed_ast = ast.parse(code)\n",
    "for node in ast.walk(parsed_ast): \n",
    "    if is_yield_from(node):\n",
    "        print('LINE {.lineno}:\\n{}\\n'.format(node, ast.dump(node)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the replacement code\n",
    "\n",
    "We now need to adapt the code provided by PEP-380 into an AST representation. \n",
    "\n",
    "Before that, however, it's important to note that the code does have one slight incompatibility with Python 2.7: it assumes that any `StopIteration` exception raised has a `.value` attribute. This value is then assigned to `RESULT` within the `RESULT = yield from EXPR` case. Since this will not be true generally in Python 2.7, let's instead make a deliberate `hasattr` check on `.value`, and assign the last yielded value from `EXPR` to `RESULT` in the case where no such attribute exists. All in all, this results in the following, slightly modified code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def g():\n",
    "    _i = iter(EXPR)\n",
    "    _r = None\n",
    "    _y = None\n",
    "    try:\n",
    "        _y = next(_i)\n",
    "    except StopIteration as _e:\n",
    "        if hasattr(_e, 'value'):  # hasattr checks are added to ease 2/3 iterator API inconsistency\n",
    "            _r = _e.value\n",
    "        else:\n",
    "            _r = _y\n",
    "    else:\n",
    "        while 1:\n",
    "            try:\n",
    "                _s = yield _y\n",
    "            except GeneratorExit as _e:\n",
    "                try:\n",
    "                    _m = _i.close\n",
    "                except AttributeError:\n",
    "                    pass\n",
    "                else:\n",
    "                    _m()\n",
    "                raise _e\n",
    "            except BaseException as _e:\n",
    "                _x = sys.exc_info()\n",
    "                try:\n",
    "                    _m = _i.throw\n",
    "                except AttributeError:\n",
    "                    raise _e\n",
    "                else:\n",
    "                    try:\n",
    "                        _y = _m(*_x)\n",
    "                    except StopIteration as _e:\n",
    "                        if hasattr(_e, 'value'):\n",
    "                            _r = _e.value\n",
    "                        else:\n",
    "                            _r = _y\n",
    "                        break\n",
    "            else:\n",
    "                try:\n",
    "                    if _s is None:\n",
    "                        _y = next(_i)\n",
    "                    else:\n",
    "                        _y = _i.send(_s)\n",
    "                except StopIteration as _e:\n",
    "                    if hasattr(_e, 'value'):\n",
    "                        _r = _e.value\n",
    "                    else:\n",
    "                        _r = _y\n",
    "                    break\n",
    "    RESULT = _r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this, we want to write a function that will take AST nodes corresponding to `EXPR` and `RESULT`, and give us back the corresponding AST for the above with those nodes appropriately inserted. The easiest way to get an AST representation of the above would be to use `ast.dump` on a parsed version, then simply duplicate this in code - but, as you might imagine, this would be extremely verbose. Furthermore, maintaining or updating this representation - suppose we wanted to assign `None` to `RESULT` when the `StopIteration.value` doesn't exist - would be pretty painful.\n",
    "\n",
    "Ideally, we would instead like to have a minimal representation of the code - essentially, what we've written above - to be used and transformed into an AST. While Python doesn't have code literals in this sense, the library [`asttools`'](https://github.com/hchasestevens/asttools) offers `quoted` and `quoted_template` decorators to do just that. These decorators transform a function body into a list of AST nodes (or, in the case of `quoted_template`, a function that will return AST nodes). As an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<_ast.Assign object at 0x7f9ece4970d0>]\n",
      "Assign(targets=[Name(id='X', ctx=Store())], value=BinOp(left=Num(n=1), op=Add(), right=Num(n=1)))\n"
     ]
    }
   ],
   "source": [
    "from asttools import quoted, quoted_template\n",
    "\n",
    "@quoted\n",
    "def simple_assignment():\n",
    "    X = 1 + 1\n",
    "    \n",
    "print(simple_assignment)\n",
    "print(ast.dump(simple_assignment[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`simple_assignment` doesn't _perform_ `X = 1 + 1` (and, indeed, [isn't a function at all anymore](the-decorators-they-wont-tell-you-about.ipynb)), but instead is the AST _representation_ of the expression `X = 1 + 1`. Likewise, with `quoted_template`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assign(targets=[Name(id='X', ctx=Store())], value=BinOp(left=Name(id='Y', ctx=Load()), op=Add(), right=Num(n=1)))\n",
      "Assign(targets=[Name(id='X', ctx=Store())], value=BinOp(left=BinOp(left=Num(n=1), op=Add(), right=Num(n=1)), op=Add(), right=Num(n=1)))\n"
     ]
    }
   ],
   "source": [
    "@quoted_template\n",
    "def simple_assignment_template(a):\n",
    "    X = a + 1\n",
    "\n",
    "name_y = ast.Name(id='Y')\n",
    "simple_assignment_ast, = simple_assignment_template(name_y)\n",
    "print(ast.dump(simple_assignment_ast))\n",
    "\n",
    "one_plus_one = ast.BinOp(\n",
    "    left=ast.Num(n=1),\n",
    "    op=ast.Add(),\n",
    "    right=ast.Num(n=1)\n",
    ")\n",
    "simple_assignment_ast, = simple_assignment_template(one_plus_one)\n",
    "print(ast.dump(simple_assignment_ast))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen, we can use this to do exactly what we were hoping - take a natural, terse, syntax-checked snippet of Python code, replace a couple of things, and return the AST. All together, it ends up looking like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<_ast.Assign at 0x7f9ece156c90>,\n",
       " <_ast.Assign at 0x7f9ece165d90>,\n",
       " <_ast.Assign at 0x7f9ece165e90>,\n",
       " <_ast.TryExcept at 0x7f9ece0f1090>,\n",
       " <_ast.Assign at 0x7f9ece0f2d90>]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@quoted_template\n",
    "def yield_from_template(EXPR, RESULT):\n",
    "    _i = iter(EXPR)\n",
    "    _r = None\n",
    "    _y = None\n",
    "    try:\n",
    "        _y = next(_i)\n",
    "    except StopIteration as _e:\n",
    "        if hasattr(_e, 'value'):\n",
    "            _r = _e.value\n",
    "        else:\n",
    "            _r = _y\n",
    "    else:\n",
    "        while 1:\n",
    "            try:\n",
    "                _s = yield _y\n",
    "            except GeneratorExit as _e:\n",
    "                try:\n",
    "                    _m = _i.close\n",
    "                except AttributeError:\n",
    "                    pass\n",
    "                else:\n",
    "                    _m()\n",
    "                raise _e\n",
    "            except BaseException as _e:\n",
    "                _x = sys.exc_info()\n",
    "                try:\n",
    "                    _m = _i.throw\n",
    "                except AttributeError:\n",
    "                    raise _e\n",
    "                else:\n",
    "                    try:\n",
    "                        _y = _m(*_x)\n",
    "                    except StopIteration as _e:\n",
    "                        if hasattr(_e, 'value'):\n",
    "                            _r = _e.value\n",
    "                        else:\n",
    "                            _r = _y\n",
    "                        break\n",
    "            else:\n",
    "                try:\n",
    "                    if _s is None:\n",
    "                        _y = next(_i)\n",
    "                    else:\n",
    "                        _y = _i.send(_s)\n",
    "                except StopIteration as _e:\n",
    "                    if hasattr(_e, 'value'):\n",
    "                        _r = _e.value\n",
    "                    else:\n",
    "                        _r = _y\n",
    "                    break\n",
    "    RESULT = _r\n",
    "\n",
    "yield_from_template(\n",
    "    ast.parse(\"(x for x in y)\").body[0],\n",
    "    ast.Name(id='_')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing the substitution procedure\n",
    "\n",
    "Now, all we have left is writing something to:\n",
    "- Grab the code of the target generator, and parse it into an AST\n",
    "- Perform the AST node replacement, using the pattern and template we described above\n",
    "- Re-compile the resultant AST and replace the original generator\n",
    "\n",
    "Thankfully, Python gives us a lot of the tools we need for this out-of-the-box. In terms of replacing a generator at definition-time, decorators provide a very nice, clean syntax for this. Grabbing the source AST can be done by using `get_ast` from [`asttools`](https://github.com/hchasestevens/asttools) - but, under the hood, all this is really doing is using [`inspect.getsource`](https://docs.python.org/2/library/inspect.html#inspect.getsource) and `ast.parse`. Transforming the AST can be done by subclassing the aptly-named [`ast.NodeTransformer`](https://docs.python.org/2/library/ast.html#ast.NodeTransformer). Finally, ASTs can be compiled into code objects via the builtins `compile` and `exec`.\n",
    "\n",
    "Putting those all together, we get the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import asttools\n",
    "\n",
    "def yield_from(expression):\n",
    "    pass  # Calls to this function are replaced with the yield_from_template via the below.\n",
    "\n",
    "class YieldFromExprReplacer(ast.NodeTransformer):\n",
    "    \"\"\"\n",
    "    Replace expressions of the form `yield_from({EXPR})` with the semantic\n",
    "    equivalent of `yield from {EXPR}` specified in PEP-380.\n",
    "    \"\"\"\n",
    "    def visit_Expr(self, node):\n",
    "        if not is_yield_from(node.value):\n",
    "            return self.generic_visit(node)\n",
    "\n",
    "        replacement_nodes = yield_from_template(\n",
    "            node.value.args[0],  # The expression being passed as the first (only) argument to yield_from.\n",
    "            ast.Name(id='_result')  # A throwaway name\n",
    "        )\n",
    "\n",
    "        # In order to replace the assignment with multiple nodes, we wrap them in an \"if 1:\" block.\n",
    "        return ast.If(\n",
    "            test=ast.Num(n=1),\n",
    "            body=replacement_nodes,\n",
    "            orelse=[]\n",
    "        )\n",
    "\n",
    "def rewrite_yield_from(fn):\n",
    "    fn_ast = asttools.get_ast(fn)\n",
    "\n",
    "    # Replace yield_from calls in function AST\n",
    "    rewritten_ast = YieldFromExprReplacer().visit(fn_ast)\n",
    "    ast.fix_missing_locations(rewritten_ast)\n",
    "\n",
    "    # Recompile rewritten AST into function object and return\n",
    "    env = sys._getframe(1).f_locals.copy()\n",
    "    env[rewrite_yield_from.__name__] = lambda x: x\n",
    "    rewritten_fn = compile(\n",
    "        ast.Module(body=[rewritten_ast]),\n",
    "        getattr(fn.__module__, '__file__', '<no_module>'),\n",
    "        'exec'\n",
    "    )\n",
    "    exec(rewritten_fn, fn.__globals__, env)\n",
    "    return env[fn.__name__]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With any luck, this should now work for both the simple and complex cases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I am outer_g',\n",
       " 'I am about to yield from inner_g',\n",
       " 'I am inner_g',\n",
       " 'I received None',\n",
       " '~fin~']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def inner_g():\n",
    "    received = yield \"I am inner_g\"\n",
    "    yield \"I received {!r}\".format(received)\n",
    "    \n",
    "@rewrite_yield_from\n",
    "def outer_g():\n",
    "    yield \"I am outer_g\"\n",
    "    yield \"I am about to yield from inner_g\"\n",
    "    yield_from(inner_g())\n",
    "    yield \"~fin~\"\n",
    "    \n",
    "[s for s in outer_g()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am outer_g\n",
      "I am about to yield from inner_g\n",
      "I am inner_g\n",
      "I received 'Hi, inner_g!'\n",
      "~fin~\n"
     ]
    }
   ],
   "source": [
    "to_send = [None, None, None, 'Hi, inner_g!', None]\n",
    "gen = outer_g()\n",
    "for value in to_send:\n",
    "    print(gen.send(value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Et voil_, the `yield from` is backported!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concluding remarks\n",
    "\n",
    "Naturally, for the convenience of those stuck maintaining Python 2.7 codebases, I have made this [`yield from` backport](https://github.com/hchasestevens/yield-from) available as a PyPI package, installable via:\n",
    "```bash\n",
    "pip install yield-from\n",
    "```\n",
    "This PyPI package also handles the case of `RESULT = yield_from(EXPR)`, which we did not cover in the above code.\n",
    "\n",
    "However, aside from the specific case of backporting `yield from`, it is hopefully clear that the AST manipulation techniques presented in this piece are applicable to a far broader range of situations - for instance, [pattern matching](https://github.com/Suor/patterns), [performance optimization](https://github.com/vstinner/fatoptimizer), [building DSLs](https://github.com/hchasestevens/xpyth), [generating javascript](http://hackflow.com/blog/2015/04/12/metaprogramming-beyond-decency-part-2/), [creating more readable tests](https://chezsoi.org/lucas/blog/pytest-ast-modification-getting-the-tests-final-code.html), and, generally, anywhere you wish Python could be doing a find-replace on your codebase for you. \n",
    "\n",
    "This is not to say that AST manipulation isn't without its drawbacks, some quite serious. Perhaps most perniciously, your source code becomes a lie: what you see is not what gets run, and oftentimes stack traces no longer line up nicely with the code you've manipulated. Furthermore, understanding the manipulation requires a lot of background knowledge (you've just read an entire article on it), placing an unavoidable and onerous expectation on anyone looking to work with or maintain the codebase - a problem, especially, for junior developers. \n",
    "\n",
    "As with any powerful tool, determining the circumstances under which the benefits AST manipulation can bring outweigh these drawbacks is best left to the discretion of you, the reader."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About the author\n",
    "* Name: [H. Chase Stevens](http://www.chasestevens.com)\n",
    "* Github: [hchasestevens](https://github.com/hchasestevens)\n",
    "* Twitter: [@hchasestevens](https://twitter.com/hchasestevens)\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
